---
title: ApiSmart Settings
description: ApiSmart Settings & Support Vendors
---

import { TipInfo } from '@/components/Tip'

ApiHug's ApiSmart leverage the [Langchain4j](https://github.com/langchain4j/langchain4j/) to talk to the LLM vendors; so basically any Langchain4j support vendor can be support by ApiSmart;

But now as limitation of our capacity; we need to add and test one by one; this will take some time;

Eventually all of them can be in our support list.

`Toolbar>ApiHug>Settings>AI`

## Settings

`Toolbar>ApiHug>Settings>AI>Settings`

Common LLM runtime settings, all of them has default value, no need to specify if keep default.

| Name              | Comment                                                                                                                                                                                                                                        | Mandatory |
|-------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------|
| Chat Memory Size  | Memory window size, default 10                                                                                                                                                                                                                 | Y         |
| Top-P             | Top-P is a text generation method that focuses on the most likely tokens until a cumulative probability threshold is reached. It helps balance diversity and certainty in generated text. Use it with care, adjusting it for desired outcomes. | Y         |
| Max Output Tokens | Maximum attempts                                                                                                                                                                                                                               | Y         |
| Timeout(s)        | Time out in second                                                                                                                                                                                                                             | Y         |
| Max Attempts      | Max attempts                                                                                                                                                                                                                                   | Y         |
| Temperature       | What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.                                                           | Y         |
| Stream            | Support stream                                                                                                                                                                                                                                 | Y         |
| System Prompt     | System prompt                                                                                                                                                                                                                                  | Y         |
| Show Detail       | Show time or token cost etc                                                                                                                                                                                                                    | Y         |


## Vendors

`Toolbar>ApiHug>Settings>AI>Vendor`

In theory [language-models](https://docs.langchain4j.dev/category/language-models) is the full list;

ApiSmart support you configure multiple instance for one LLM vendor, like for different env;

so each setting will have a specific name and description, you should make them straightforward for example `Openai-test-env` will be a good sample.


| Name        | Comment                               | Mandatory |
|-------------|---------------------------------------|-----------|
| Name        | Name of this LLM configuration        | Y         |
| Description | Description of this LLM configuration | N         |



### OpenAI

| Name         | Comment                              | Mandatory |
|--------------|--------------------------------------|-----------|
| URL          | `https://api.openai.com/` as default | N         |
| Api Key      | Key for the API                      | Y         |
| Project Id   | Not used yet                         | N         |
| Organization | Not used yet                         | N         |


### Azure AI

| Name         | Comment                                                         | Mandatory |
|--------------|-----------------------------------------------------------------|-----------|
| URL          | `https://***.openai.azure.com/` like endpoint                   | Y         |
| Api Key      | Key for the API                                                 | Y         |
| Model        | Default Model name(deployment), you can put manually on runtime | N         |


### LLM Studio

| Name         | Comment                                                         | Mandatory |
|--------------|-----------------------------------------------------------------|-----------|
| URL          | `http://localhost:1234/v/1/` default local URL                  | Y         |

[lmstudio](https://lmstudio.ai/) Discover, download, and run local LLMs

[Local LLM Server](https://lmstudio.ai/docs/basics/server), You can serve local LLMs from LM Studio's Developer tab, either on localhost or on the network.

### Jan

| Name         | Comment                                                         | Mandatory |
|--------------|-----------------------------------------------------------------|-----------|
| URL          | `https://***.openai.azure.com/` like endpoint                   | Y         |

[Enable the Jan API Server](https://jan.ai/integrations/coding/continue-dev#step-2-enable-the-jan-api-server)

### OpenRouter

**TBD**

| Name         | Comment                                                         | Mandatory |
|--------------|-----------------------------------------------------------------|-----------|
| URL          | `https://***.openai.azure.com/` like endpoint                   | Y         |
| Api Key      | Key for the API                                                 | Y         |
| Model        | Default Model name(deployment), you can put manually on runtime | N         |


### Qianfan

| Name       | Comment                                              | Mandatory |
|------------|------------------------------------------------------|-----------|
| Api Key    | Key for the API                                      | Y         |
| Secret Key | Secret Key for the API                               | Y         |
| Model      | default model, you can input manually during runtime | Y         |

[百度智能云千帆大模型](https://console.bce.baidu.com/qianfan/ais/console/applicationConsole/application)

BTW `Yi-34B-Chat` is free;

### Zhipu


<img src={require('@/img/editor/054_ai_zhipu.gif').default.src} alt="ApiHug Zhipu AI" width={2362} height={1608}
     className="rounded-lg"/>

| Name       | Comment                                              | Mandatory |
|------------|------------------------------------------------------|-----------|
| Api Key    | Key for the API                                      | Y         |
| Model      | default model, you can input manually during runtime | Y         |


1. [ApiKey](https://www.bigmodel.cn/usercenter/apikeys)
2. [Register](https://www.bigmodel.cn/invite?icode=jo8%2FWK7FG7riwcqcY0VTu33uFJ1nZ0jLLgipQkYjpcA%3D)


### TBD

1. Google
2. ...

## Prompt

`Toolbar>ApiHug>Settings>AI>Prompt`

| Name   | Comment                                                                       | Mandatory |
|--------|-------------------------------------------------------------------------------|-----------|
| name   | shortcut style, can be refer `/{name}` when ask, `/explain` is a good example | Y         |
| prompt | body of the prompt                                                            | Y         |

---

⚠️Ensure **name** is short, unique, and easily recognizable⚠️


<TipInfo>
  The quality of prompt words directly affects the effectiveness of the answers produced by large models;
  
  this is a task that requires patience and experience!
  
  If you don't ask good questions, of course, you won't get good answers.
</TipInfo>



[Prompt-Engineering-Guide-git](https://github.com/dair-ai/Prompt-Engineering-Guide)

Prompt engineering is a relatively new discipline for developing and optimizing prompts to efficiently use language models (LMs) for a wide variety of applications and research topics. 

Prompt engineering skills help to better understand the capabilities and limitations of large language models (LLMs).


We will collect some tips here: [apismart prompts](https://github.com/apihug/apismart-prompts/)

---

ApiHug `api/` prompt ([apismart-prompts/api](https://github.com/apihug/apismart-prompts/blob/main/src/api/api.md)):


**BEGIN**

You are an experienced ApiHug developer skilled in OpenAPI design using ApiHug, a DSL for defining APIs with Protocol Buffers in a structured style.

For example, consider the following Proto definition:

```proto3
  rpc SayHello (google.protobuf.Empty) returns (google.protobuf.Empty) {
    option (hope.swagger.operation) = {
      get: "/say-hello";
      description: "Hello from ApiHug";
      tags: "project";
      priority: MIDDLE;
      pageable: true;
      authorization:{
        low_limit_risky_mode: ANONYMOUS
      }
    };
  };
```



This is equivalent to the standard OpenAPI definition:

```json

"/say-hello": {
      "get": {
        "summary": "Say Hello",
        "description": "Hello from ApiHug",
        "tags": ["project"],
        "responses": {
          "200": {
            "description": "Successful response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Empty"
                }
              }
            }
          }
        },
        "security": [
          {
            "anonymous": []
          }
        ]
      }
    }
```

Some standard you need to follow:

1. Syntax must follow `proto3` standard
2. Post body define in rpc request while response in rpc return
3. Support pageable, or input output as plural
4. Always define the Message and Service separately

Please provide accurate and relevant information regarding OpenAPI and ApiHug code standards.

Do not include any unrelated information or references to external websites.

**END**


