---
title: ApiSmart 配置
description: ApiSmart 配置和支持的LLM供应商
---
import { TipInfo } from '@/components/Tip'

ApiHug 的 ApiSmart 利用 [Langchain4j](https://github.com/langchain4j/langchain4j/) 与大型语言模型（LLM）供应商进行通信；因此基本上任何 Langchain4j 支持的供应商都可以被 ApiSmart 支持；

但由于我们目前的能力有限，我们需要逐个添加和测试，这将需要一些时间；

最终，所有这些供应商都能够进入我们的支持列表。

`Toolbar>ApiHug>Settings>AI`

## Settings


`Toolbar>ApiHug>Settings>AI>Settings`

常见的大型语言模型（LLM）运行时设置，它们都有默认值，如果不需要更改默认设置，则无需特别指定。

| Name              | Comment                                                                                                                                                                                                                                        | Mandatory |
|-------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------|
| Chat Memory Size  | Memory window size, default 10                                                                                                                                                                                                                 | Y         |
| Top-P             | Top-P is a text generation method that focuses on the most likely tokens until a cumulative probability threshold is reached. It helps balance diversity and certainty in generated text. Use it with care, adjusting it for desired outcomes. | Y         |
| Max Output Tokens | Maximum attempts                                                                                                                                                                                                                               | Y         |
| Timeout(s)        | Time out in second                                                                                                                                                                                                                             | Y         |
| Max Attempts      | Max attempts                                                                                                                                                                                                                                   | Y         |
| Temperature       | What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.                                                           | Y         |
| Stream            | Support stream                                                                                                                                                                                                                                 | Y         |
| System Prompt     | System prompt                                                                                                                                                                                                                                  | Y         |
| Show Detail       | Show time or token cost etc                                                                                                                                                                                                                    | Y         |


## Vendors

支持列表:

1. Open AI
2. Azure
3. Gemini
4. Anthropic
5. DeepInfra
6. Mooshot
7. Zhipu
8. DeepSeek
9. Qianfan
10. Grop
11. Ollama
12. Mistral
13. LMStudio
14. OpenRouter
15. Jan
16. GPT4All
17. Tongyi(Aliyun)通义-阿里
18. Hunyuan(Tencent)混元-腾讯

其他供应商只要支持 OpenAI 风格API 均可无缝接入。


`Toolbar>ApiHug>Settings>AI>Vendor`

In theory [language-models](https://docs.langchain4j.dev/category/language-models) is the full list;

ApiSmart 支持您为同一个大型语言模型（LLM）供应商配置多个实例，例如用于不同的环境；

因此，每个设置都将具有特定的名称和描述，您应该使它们简单明了。例如，`Openai-test-env` 是一个很好的示例。


| Name        | Comment                               | Mandatory |
|-------------|---------------------------------------|-----------|
| Name        | Name of this LLM configuration        | Y         |
| Description | Description of this LLM configuration | N         |



### OpenAI

| Name         | Comment                              | Mandatory |
|--------------|--------------------------------------|-----------|
| URL          | `https://api.openai.com/` as default | N         |
| Api Key      | Key for the API                      | Y         |
| Project Id   | Not used yet                         | N         |
| Organization | Not used yet                         | N         |


### Azure AI

| Name         | Comment                                                         | Mandatory |
|--------------|-----------------------------------------------------------------|-----------|
| URL          | `https://***.openai.azure.com/` like endpoint                   | Y         |
| Api Key      | Key for the API                                                 | Y         |
| Model        | Default Model name(deployment), you can put manually on runtime | N         |


### Moonshot

| Name         | Comment                                                         | Mandatory |
|--------------|-----------------------------------------------------------------|-----------|
| URL          | `https://api.moonshot.cn/v1` like endpoint                   | Y         |
| Api Key      | Key for the API                                                 | Y         |
| Model        | Default Model name(deployment), you can put manually on runtime | N         |

- [moonshot api-key](https://platform.moonshot.cn/console/api-keys)
- [moonshot doc](https://platform.moonshot.cn/docs/intro)


### LLM Studio

| Name         | Comment                                                         | Mandatory |
|--------------|-----------------------------------------------------------------|-----------|
| URL          | `http://localhost:1234/v/1/` default local URL                  | Y         |

[lmstudio](https://lmstudio.ai/) Discover, download, and run local LLMs

[Local LLM Server](https://lmstudio.ai/docs/basics/server), You can serve local LLMs from LM Studio's Developer tab, either on localhost or on the network.

### Jan

| Name         | Comment                                                         | Mandatory |
|--------------|-----------------------------------------------------------------|-----------|
| URL          | `https://***.openai.azure.com/` like endpoint                   | Y         |

[Enable the Jan API Server](https://jan.ai/integrations/coding/continue-dev#step-2-enable-the-jan-api-server)

### OpenRouter

**TBD**

| Name         | Comment                                                         | Mandatory |
|--------------|-----------------------------------------------------------------|-----------|
| URL          | `https://***.openai.azure.com/` like endpoint                   | Y         |
| Api Key      | Key for the API                                                 | Y         |
| Model        | Default Model name(deployment), you can put manually on runtime | N         |


### Qianfan

| Name       | Comment                                              | Mandatory |
|------------|------------------------------------------------------|-----------|
| Api Key    | Key for the API                                      | Y         |
| Secret Key | Secret Key for the API                               | Y         |
| Model      | default model, you can input manually during runtime | Y         |

[百度智能云千帆大模型](https://console.bce.baidu.com/qianfan/ais/console/applicationConsole/application)

BTW `Yi-34B-Chat` is free;


### Zhipu


<img src={require('@/img/editor/054_ai_zhipu.gif').default.src} alt="ApiHug Zhipu AI" width={2362} height={1608}
     className="rounded-lg"/>

| Name       | Comment                                              | Mandatory |
|------------|------------------------------------------------------|-----------|
| Api Key    | Key for the API                                      | Y         |
| Model      | default model, you can input manually during runtime | Y         |


1. [ApiKey](https://www.bigmodel.cn/usercenter/apikeys)
2. [Register](https://www.bigmodel.cn/invite?icode=jo8%2FWK7FG7riwcqcY0VTu33uFJ1nZ0jLLgipQkYjpcA%3D)


### TBD

1. Google
2. ...

## Prompt

`Toolbar>ApiHug>Settings>AI>Prompt`

| Name   | Comment                                                                       | Mandatory |
|--------|-------------------------------------------------------------------------------|-----------|
| name   | shortcut style, can be refer `/{name}` when ask, `/explain` is a good example | Y         |
| prompt | body of the prompt                                                            | Y         |

⚠️保证 **name** 简短，唯一，易识别⚠️

<TipInfo>
  
  提示词的好坏直接影响大模型出答案的效果，这是个需要耐心和经验的活！
  
  问不好问题，当然得不到好的答案
</TipInfo>

[Prompt-Engineering-Guide-git](https://github.com/dair-ai/Prompt-Engineering-Guide)  &  [promptingguide - web](https://www.promptingguide.ai/zh/)

提示工程（Prompt Engineering）是一门较新的学科，关注提示词开发和优化，帮助用户将大语言模型（Large Language Model, LLM）用于各场景和研究领域。 

掌握了提示工程相关技能将有助于用户更好地了解大型语言模型的能力和局限性。

部分罗列这里: [apismart prompts](https://github.com/apihug/apismart-prompts/) ; [提示工程-Bigmodel](https://www.bigmodel.cn/dev/howuse/prompt)

---


ApiHug `api/` 指令 ([apismart-prompts/api](https://github.com/apihug/apismart-prompts/blob/main/src/api/api.md)):

**BEGIN**

As a seasoned ApiHug developer, you'll design API endpoints using ApiHug's Protocol Buffers-based DSL.

Here is an example of a Proto definition using ApiHug:

```protobuf
syntax = "proto3";

package com.apihug.sample;

import "extend/domain.proto";
import "google/protobuf/empty.proto";
import "swagger/annotations.proto";

service SampleService {
  option (hope.swagger.svc) = {
    path: "/sample";
    description: "Service for Sample";
    tag:{
      name: "demo"
      description: "all demo apis"
    }
  };

  rpc ExampleSayHello (google.protobuf.Empty) returns (google.protobuf.Empty) {
    option (hope.swagger.operation) = {
      get: "/hello-world";
      description: "Say hello to the world";
      tags: "project";
      pageable: true;
      input_plural: true;
      out_plural: false;
      priority: HIGH;
      //only include this part, when you really need pass parameters
      parameters:{
        parameter:{
          name: "name";
          in: QUERY;
          schema:{
            format: STRING;
            blank: FALSE
          }
        }
      }
     //only include this part, when you need authorization
     authorization:{
        //low_limit_risky_mode: LOGIN
        rbac:{
          roles: {
            roles: 'USER_ADD'
          }
        }
     }
    };
  };
}

```

## Basic Tips

### `hope.swagger.svc`

Specify the base path, description, and tags for your service.

### `hope.swagger.operation`

Specify HTTP method, summary, and parameters with the `Operation` message. Omit `bool` properties with default `false`.

```protobuf
message Operation {
  repeated string tags = 1;
  string summary = 2;
  string description = 3;
  map<string, Response> responses = 9;
  repeated Scheme schemes = 10;
  bool deprecated = 11;
  Priority priority = 14; //LOW,MIDDE,HIGH,CRITICAL,FATAL
  string request_name = 15;
  optional bool pageable = 51; //Pageable request and response, default false
  optional bool raw = 52; //keep raw response 
  optional bool request = 53;
  optional bool input_plural = 56; //Input is a List, only set when need
  optional bool out_plural = 57; //Output is a list, only set when need
  optional Parameters parameters = 100;
  oneof pattern {
    string get = 302;
    string put = 303;
    string post = 304;
    string delete = 305;
    string patch = 306;
  }
  optional Authorization authorization = 402;
  bool body_empty = 600;
  repeated string questions = 800; //Tips for AI prompt for this operation
}
```

### `authorization`

Set API security and authorization with `Authorization` messages, avoiding OAS methods in favor of the ApiHug approach.

```protobuf

message RBAC {
  enum Combinator {
    AND = 0;
    OR = 1;
  }

  enum PredefinedRoleCheckerType {
    NA = 0 [deprecated = true];
    PLATFORM = 1;
    PLATFORM_MANAGER = 2;
    PLATFORM_OWNER = 3;
    TENANT = 4;
    TENANT_MANAGER = 5;
    TENANT_OWNER = 6;
  }

  message Roles {
    repeated string roles = 1;
  }

  oneof role {
    PredefinedRoleCheckerType predefined_role_checker = 3;
    Roles roles = 2;
  }

message Authorization {
  enum LowLimitRiskyMode {
    ANONYMOUS = 0;
    LOGIN = 1;
    ACTIVE = 2;
  }
  oneof kind {
    LowLimitRiskyMode low_limit_risky_mode = 1;
    RBAC rbac = 2;
    string expression = 15;
  }
}
```

### `parameters`

- Use `Parameters` and `Parameter` to define API parameters and responses.
- Omit parameter definitions if not required, especially for POST requests where input and output are specified in the rpc method.

```protobuf
message Parameters {
  repeated Parameter parameter = 1;
}

message Parameter {
  enum IN {
    QUERY = 0;
    HEADER = 1;
    PATH = 2;
    COOKIE = 3;
    SESSION = 4;
  }
  string name = 1;
  IN in = 2;
  JSONSchema schema = 10;
  hope.common.BoolType plural = 20;
}
```

### RPC `returns` or input

Define the JSON schema for your API using the `JSONSchema` message. This includes details like the title, description, and format of the schema.

```protobuf
enum JSONSchemaFormat {
    //Not used, default to string or the explicit type of the field in the message
    UNKNOWN = 0;
    //what we care about
    //same: `format = bool`
    BOOLEAN = 4;
    //same: `format = int32`
    INTEGER = 5;
    //same: `format = double`
    DOUBLE = 6;
    STRING = 7;
    //same: `format = float`
    FLOAT = 8;
    //same: `format = big-decimal`
    BIG_DECIMAL = 9;
    //same: `format = int64`
    LONG = 10;
    //same: `format = date`
    DATE = 11;
    //same: `format = date-time`
    DATE_TIME = 12;
    //same: `format = time`
    TIME = 13;
    //same: `format = uuid`
    UUID = 14;
    //same: `format = password`
    PASSWORD = 15;
    //same: `format = email`
    EMAIL = 16;
    //same: `format = binary`
    BINARY = 17;
  }
message JSONSchema {
  string ref = 3;
  string title = 5;
  string description = 6;
  string default = 7;
  bool read_only = 8;
  string example = 9;
  google.protobuf.DoubleValue multiple_of = 10;
  google.protobuf.DoubleValue maximum = 11;
  hope.common.BoolType exclusive_maximum = 12;
  google.protobuf.DoubleValue minimum = 13;
  hope.common.BoolType exclusive_minimum = 14;
  google.protobuf.UInt64Value max_length = 15;
  google.protobuf.UInt64Value min_length = 16;
  string pattern = 17;
  google.protobuf.UInt64Value max_items = 20;
  google.protobuf.UInt64Value min_items = 21;
  hope.common.BoolType unique_items = 22;
  google.protobuf.UInt64Value max_properties = 24;
  google.protobuf.UInt64Value min_properties = 25;
  repeated string required = 26;
  repeated string array = 34;
  JSONSchemaFormat format = 36;
  repeated string enum = 46;
  FieldConfiguration field_configuration = 1001;
  hope.common.BoolType empty = 48;
  hope.common.BoolType blank = 49;
  hope.common.BoolType assert = 1011;
  string decimal_max = 1012;
  string decimal_min = 1013;
  google.protobuf.Int32Value digits_integer = 1014;
  google.protobuf.Int32Value digits_fraction = 1015;
  hope.common.BoolType email = 1016;
  optional TimeConstraintType time_constraint_type = 1017;
  oneof format_of_date {
    DateFormat date_format = 1018;
    string customized_date_format = 1019;
  }
  optional mock.Mock mock = 1020;
}
```

This is a Sample:

```protobuf
message SampleRequest {
  option (hope.swagger.schema) = {
    json_schema: {
      description: "A sample plain object definition";
    };
  };
  uint64 age = 1 [(hope.swagger.field) = {
    description: "age of human";
    example: "Example of this field";
    empty: FALSE;
  }];

  string name = 2 [(hope.swagger.field) = {
    description: "name of a chinese people";
    mock:{
      chinese_name_rule:{
        type: NAME
      }
    }
  }];
}
```

###  Date Formats

Define date formats using the `DateFormat` enum for consistency across your API.
```protobuf
enum DateFormat {
  BASIC_ISO_DATE = 0;
  ISO_LOCAL_DATE = 1;
  ISO_TIME = 2;
  ISO_LOCAL_TIME = 3;
  ISO_LOCAL_DATE_TIME = 7;
  YYYY_MM_DD_HH_MM_SS = 15;
  YYYY_MM_DD_HH_MM_SS_SSS = 16;
  SLASH_YYYY_MM_DD = 17;
  SLASH_YYYY_MM_DD_HH_MM_SS = 18;
  SLASH_YYYY_MM_DD_HH_MM_SS_SSS = 19;
  HH_MM = 20;
}
```




## Standards Compliance

1. Use proto3 syntax for all protocol buffer definitions.
2. Ensure precise and meaningful names and descriptions in API definitions.
3. Adhere strictly to the ApiHug and OpenAPI specification.

**END**
